{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중간고사 대체 과제: FashionMNIST 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 필수 패키지 임포트\n",
    "\n",
    "tensorflow 패키지와 코드에서 사용되는 클래스 및 함수를 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HryrObMTgBpH"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 실험 환경 설정\n",
    "\n",
    "딥러닝 프로젝트는 많은 환경 변수를 필요로 합니다. 실험 환경과 관련된 변수를 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터세트 설정\n",
    "num_train_samples = 55000\n",
    "batch_size = 100\n",
    "input_dim = 784\n",
    "num_classes = 10\n",
    "\n",
    "# 모델 설정\n",
    "hidden_dim = 200\n",
    "\n",
    "# 훈련 설정\n",
    "epochs = 30\n",
    "lr = 1e-2\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터처리 파이프라인 구현\n",
    "\n",
    "FashionMNIST 데이터세트를 다운받고 데이터처리 파이프라인을 작성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egbBm8VbX3CB"
   },
   "outputs": [],
   "source": [
    "# Fashion MNIST 데이터세트 다운로드\n",
    "(train_image, train_label), (test_image, test_label) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fahsion MNIST 데이터세트 확인\n",
    "print('훈련 이미지: ', train_image.shape)\n",
    "print('테스트 이미지: ', test_image.shape)\n",
    "print('훈련 라벨: ', train_label.shape)\n",
    "print('테스트 라벨: ', test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nl6FjMqFaJEK"
   },
   "outputs": [],
   "source": [
    "# 훈련세트를 훈련세트 / 검증세트로 분할\n",
    "valid_image = train_image[num_train_samples:, :, :]\n",
    "valid_label = train_label[num_train_samples:]\n",
    "train_image = train_image[:num_train_samples, :, :]\n",
    "train_label = train_label[:num_train_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_eC_NzVwgTMP"
   },
   "outputs": [],
   "source": [
    "# 데이터처리 파이프라인 1: tensorflow Dataset 클래스 생성 \n",
    "train_dataset = Dataset.from_tensor_slices((train_image, train_label))\n",
    "valid_dataset = Dataset.from_tensor_slices((valid_image, valid_label))\n",
    "test_dataset = Dataset.from_tensor_slices((test_image, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "go9AVlq4cUWr"
   },
   "outputs": [],
   "source": [
    "# 데이터처리 파이프라인 2: 전처리함수 및 미니배치 그룹핑 \n",
    "def preprocess(image, label):\n",
    "    \"\"\" 이미지, 라벨 전처리 과정\n",
    "        1) 이미지 자료형 변환: 'uint8' -> 'float32'\n",
    "        2) 이미지 값 범위 정규화: 0 ~ 255 -> 0 ~ 1\n",
    "        3) 이미지 크기 변환: (28, 28) -> (784,)\n",
    "        4) 라벨을 원핫벡터로 변환\n",
    "    \"\"\"\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.0\n",
    "    image = tf.reshape(image, (input_dim,))\n",
    "    label = tf.one_hot(label, depth=num_classes, dtype=tf.float32)\n",
    "    return image, label\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.shuffle(len(train_dataset))\n",
    "train_dataset = train_dataset.batch(batch_size)\n",
    "\n",
    "valid_dataset = valid_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "test_dataset = test_dataset.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 모델 구현\n",
    "\n",
    "1개의 은닉층과 1개의 출력층으로 구성된 Multilayer Perceptron (MLP) 모델을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L0HMAGbqlGQM"
   },
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "inputs = Input(shape=(input_dim,), name='input')\n",
    "x = Dense(hidden_dim, activation='relu', name='hidden1')(inputs)\n",
    "x = Dense(num_classes, activation=\"softmax\", name='output')(x)\n",
    "model = Model(inputs, x, name='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 평가지표, 손실함수, 학습률 스케쥴러, 최적화 알고리즘 구현\n",
    "\n",
    "모델 훈련 및 평가에 필요한 평가지표, 손실함수를 정의하고 학습률 스케쥴러 및 SGD 최적화 알고리즘을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표 정의\n",
    "metric = CategoricalAccuracy()\n",
    "\n",
    "# 손실함수 정의\n",
    "loss = CategoricalCrossentropy()\n",
    "\n",
    "# 학습률 스케쥴러 정의\n",
    "lr_schedule = CosineDecay(lr, len(train_dataset) * epochs)\n",
    "\n",
    "# 최적화 알고리즘 정의\n",
    "optimizer = SGD(lr_schedule, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델 학습 및 평가\n",
    "\n",
    "Keras API를 이용하기 위해 모델 compile을 수행하고, 모델 훈련과 성능 평가를 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suGitB3PlXti"
   },
   "outputs": [],
   "source": [
    "# 모델 컴파일\n",
    "model.compile(optimizer=optimizer, \n",
    "              loss=loss, \n",
    "              metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AU2RjjGhqS0s"
   },
   "outputs": [],
   "source": [
    "# 모델 훈련\n",
    "history = model.fit(train_dataset, epochs=epochs, validation_data=valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0uo3UV4sqjJ"
   },
   "outputs": [],
   "source": [
    "# 학습과정을 시각화하여 손실함수 및 정확도의 변화추이를 분석해봅니다.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "losses = pd.DataFrame({\n",
    "    'train_loss': history.history['loss'], \n",
    "    'valid_loss': history.history['val_loss'],\n",
    "})\n",
    "accuracies = pd.DataFrame({\n",
    "    'train_acc': history.history['categorical_accuracy'], \n",
    "    'valid_acc': history.history['val_categorical_accuracy'],\n",
    "})\n",
    "\n",
    "losses.plot(figsize=(8, 6))\n",
    "plt.grid(True)\n",
    "plt.gca().set_xlim(0, 15)\n",
    "plt.show()\n",
    "\n",
    "accuracies.plot(figsize=(8, 6))\n",
    "plt.grid(True)\n",
    "plt.gca().set_xlim(0, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M3RwfGCeuZro"
   },
   "outputs": [],
   "source": [
    "# 학습된 모델의 성능을 테스트 세트에서 평가합니다.\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 추론하기\n",
    "\n",
    "학습된 모델을 이용하여 새로운 이미지의 클래스 라벨을 예측합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WnD1eb270lHk"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "new_input = test_image[0, :, :]\n",
    "new_input = tf.cast(new_input, tf.float32) / 255.0\n",
    "new_input = tf.reshape(new_input, (1, 784))\n",
    "prediction = model.predict(new_input)\n",
    "\n",
    "# Visualize\n",
    "for i in range(28):\n",
    "    x = ''\n",
    "    for j in range(28):\n",
    "        x += f'{test_image[0, i, j]:3} '\n",
    "    print(x)\n",
    "\n",
    "x = ''\n",
    "for i in range(10):\n",
    "    x += f'{prediction[0, i]:.2f} '\n",
    "print(x)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week 6 - Fashion-MNIST Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
